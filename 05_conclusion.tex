%TODO die unterkapitel hier nicht zu nummerien ist evt sinnvoll?
\chapter{Conclusion}
\par
Before discussing the feasibility of the single aspects we have outlined so far, we want to resume in brief the main idea behind the vision for DSL’s and the outlined points so far.
\par
Environmental modelers are nowadays forced, to implement their models with standard programming languages. Since they are often not familiar with designing and handling large software projects and the programming itself, this is a very time consuming process. This leads to poor implemented models, that are inefficient, not stable and not exchangeable.
\par
The underlying and fundamental issue with this current modeling workflow is, that modelers aren’t able to concentrate on their origin task the modeling, since they don't have tools that allow the implementation in a modeler friendly way. Therefore we outlined, based on the ideas of Athanasiadis and summarized in 
%TODO ref to chapter
 chapter XX, a modeling workflow that makes use of an highly customized IDE. This IDE and the tools it encompasses could bridge the gap of modelers origin intention and the tool support that is needed (see chapterXX ).
%TODO ref to chapter
\par
After this more overlooking chapter, we have discussed several ways how the very crucial points of this IDE, the DSL and its connection to the ontology, could be solved. To complete things,we want to summarize and discuss our thoughts on the feasibility of the requirements, the ideas mentioned outlining a toolchain and approaches of DSL creation and ontology connection in the following section. After that, we want to give some personal notes to the project procedure itself. 
\section{Notes on the Feasibility}
\par
%TODO refs to chapters (XX)
If we look back to the requirements explained in chapter XX. The first requirement was to allow the user to semantically describe domain specific data structures. We think that this feature is realisable in principal. In chapter XX we have already discussed a promising approach how this can be achieved. Neither a more detailed discussion of this point nor an example that proves that the worked out approach is realizable could not be done unfortunately. This is a result of the very short project time and the very rudimentary previous knowledge of the project team.  As mentioned in chapter XX, there a lot of open questions and open work that need to be done. For example it is necessary to define a stringent structure of the ontologies in order to allow processing by the code generator which is a very difficult, time and resource intensive task. Another possible problem could be the size of the ontology. If we regard that the mentioned NASA SWEET ontology set comprises about 200 different ontologies and it must be possible for users to add their own semantical data type descriptions, it could be a very challenging task to keep the processing fast and reliable. The same problem could be the inverse direction. A model could easily consist of a hundred entities and if all these entities are mapped into the ontology to the reasoning service this could be a very time consuming task, which is barely influenceable since the reasoning functionality is almost implemented in third party libraries.
\par
As we have already discussed, the second requirement is rich model interfaces which is in our opinion also feasible and realisable. We came to this conclusion since there are projects that already implement such features (OpenMI) on the one hand and the underlying problem is similar to the service oriented architecture paradigm, where all these problems are already solved, on the other hand. We believe, that the main remaining challenge is, that there is a huge need for standards that are broadly accepted. Only if such standards are developed and used, there is a chance that features like exchanging models or automatically composing them like it can be done with web services can be developed successfully.\\
A good way how the integration into the DSL, which means the way the user can define the corresponding metadata to the model, could be done is to provide the user with a set of annotations. An example that also uses annotations to describe metadata of the implemented models is the OMS project.
\par
Regarding the requirement that the DSL should be able to handle typical operations on its own, we think that this in general feasible with the worked mapping solution between DSL and ontology. For example let us suppose that in the ontology is modeled in such way that a temperature can have several units such as Kelvin, Celsius and Fahrenheit and how these units can be converted into another. Exactly this example is already covered by the NASA Sweet ontologies. If the user now wants to add two different temperature values, the code generator could check that they have the same units using the object model generated, and if not convert them into the same unit before adding them. This process could be completely transparent to the user. Again we are not sure how many and how complex problems would appear when trying to implement this due to the limited project period and missing experience in this field. Moreover we think that it is very difficult to generally offer such typical operations, which hides side effects like unit conversions or interpolation from the user. For us it not clear where and how such internal features can be balanced to facilitate the user instead of interfering him.
\par
One open question is how to achieve a DSL that is aware of different modeling paradigms and frameworks. We have omitted that feature totally because we have believed that it would just complicate matters without bringing a real benefit regarding the feasibility of all other issues. Of course it is clear that this point would strongly increase the complexity of designing a DSL and maybe it is impossible. For us this seems to be one of the hardest and most complex problems to solve, especially since we didn’t found an example for a DSL that allows multiple modelling paradigms during the research belonging to all other issues.
\par
Also for the last two requirements, account for modeling uncertainty and model transparency and defensibility of results we only worked out some very rough ideas and are not sure if they can be implemented in that way. Hence it is very difficult to say at this point if these features are realisable and we think that there is some open work to answer these questions.
\par %TODO grdive kommentar: say that it could be risky triying to implement this
To put it in a nutshell, we have worked out some very promising ideas and concepts for some of the key features of the vision for the DSL, so that we believe that the essential parts of the general ideas, like adding semantic data types and so on, are realisable at least. But we are not sure how many and how complex problems would appear trying to implement these concepts. And we think that trying to implement this feature is a very time consuming and resource intensive. Besides that, for us it was not possible to analyze the feasibility of other also important but not so essential features such as model uncertainty and model transparency due to the very limited project period and the very low domain skills at the very beginning of the project.  

\section{Thoughts on the project}
%TODO bitte meine gedanken lesen.

