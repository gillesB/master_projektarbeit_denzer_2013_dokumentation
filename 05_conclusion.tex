%TODO die unterkapitel hier nicht zu nummerien ist evt sinnvoll?
\chapter{Conclusion}
\par
Before discussing the feasibility of the single aspects we have outlined so far, we want to resume in brief the main idea behind the vision for DSL’s and the outlined points so far.
\par
Environmental modelers are nowadays forced, to implement their models with standard programming languages. Since they are often not familiar with designing and handling large software projects and the programming itself, this is a very time consuming process. This leads to poor implemented models, that are inefficient, not stable and not exchangeable.
\par
The underlying and fundamental issue with this current modeling workflow is, that modelers aren’t able to concentrate on their origin task the modeling, since they don't have tools that allow the implementation in a modeler friendly way. Therefore we outlined, based on the ideas of Athanasiadis and summarized in section \ref{sec:vision_for_a_dsl}, a modeling workflow that makes use of an highly customized IDE. This IDE and the tools it encompasses could bridge the gap of modelers origin intention and the tool support that is needed (see chapter \ref{chap:toolchain} ).
\par
After this more overlooking chapter, we have discussed several ways how the very crucial points of this IDE, the DSL and its connection to the ontology, could be solved. To complete things,we want to summarize and discuss our thoughts on the feasibility of the requirements, the ideas mentioned outlining a toolchain and approaches of DSL creation and ontology connection in the following section. After that, we want to give some personal notes to the project procedure itself. 
\section{Notes on the Feasibility}
\par
%TODO refs to chapters (XX)
If we look back to the requirements explained in the section \ref{sec:vision_for_a_dsl}. The first requirement was to allow the user to semantically describe domain specific data structures. We think that this feature is realisable in principal. In chapter \ref{chap:toolchain} we have already discussed a promising approach how this can be achieved. Neither a more detailed discussion of this point nor an example that proves that the worked out approach is realizable could not be done unfortunately. This is a result of the very short project time and the very rudimentary previous knowledge of the project team.  As mentioned in chapter XX, there are a lot of open questions and open work that need to be done. For example it is necessary to define a stringent structure of the ontologies in order to allow processing by the code generator which is a very difficult, time and resource intensive task. Another possible problem could be the size of the ontology. If we regard that the mentioned NASA SWEET ontology set comprises about 200 different ontologies and it must be possible for users to add their own semantical data type descriptions, it could be a very challenging task to keep the processing fast and reliable. The same problem could be the inverse direction. A model could easily consist of a hundred entities and if all these entities are mapped into the ontology to the reasoning service this could be a very time consuming task, which is barely influenceable since the reasoning functionality is almost implemented in third party libraries.
\par
As we have already discussed, the second requirement is rich model interfaces which is in our opinion also feasible and realisable. We came to this conclusion since there are projects that already implement such features (OpenMI) on the one hand and the underlying problem is similar to the service oriented architecture paradigm, where all these problems are already solved, on the other hand. We believe, that the main remaining challenge is, that there is a huge need for standards that are broadly accepted. Only if such standards are developed and used, there is a chance that features like exchanging models or automatically composing them like it can be done with web services can be developed successfully.\\
A good way how the integration into the DSL, which means the way the user can define the corresponding metadata to the model, could be done is to provide the user with a set of annotations. An example that also uses annotations to describe metadata of the implemented models is the OMS project.
\par
Regarding the requirement that the DSL should be able to handle typical operations on its own, we think that this in general feasible with the worked mapping solution between DSL and ontology. For example let us suppose that in the ontology is modeled in such way that a temperature can have several units such as Kelvin, Celsius and Fahrenheit and how these units can be converted into another. Exactly this example is already covered by the NASA Sweet ontologies. If the user now wants to add two different temperature values, the code generator could check that they have the same units using the object model generated, and if not convert them into the same unit before adding them. This process could be completely transparent to the user. Again we are not sure how many and how complex problems would appear when trying to implement this due to the limited project period and missing experience in this field. Moreover we think that it is very difficult to generally offer such typical operations, which hides side effects like unit conversions or interpolation from the user. For us it not clear where and how such internal features can be balanced to facilitate the user instead of interfering him.
\par
One open question is how to achieve a DSL that is aware of different modeling paradigms and frameworks. We have omitted that feature totally because we have believed that it would just complicate matters without bringing a real benefit regarding the feasibility of all other issues. Of course it is clear that this point would strongly increase the complexity of designing a DSL and maybe it is impossible. For us this seems to be one of the hardest and most complex problems to solve, especially since we didn’t found an example for a DSL that allows multiple modelling paradigms during the research belonging to all other issues.
\par
Also for the last two requirements, account for modeling uncertainty and model transparency and defensibility of results we only worked out some very rough ideas and are not sure if they can be implemented in that way. Hence it is very difficult to say at this point if these features are realisable and we think that there is some open work to answer these questions.
\par %TODO grdive kommentar: say that it could be risky triying to implement this
To put it in a nutshell, we have worked out some very promising ideas and concepts for some of the key features of the vision for the DSL, so that we believe that the essential parts of the general ideas, like adding semantic data types and so on, are realisable at least. But we are not sure how many and how complex problems would appear trying to implement these concepts. And we think that trying to implement this feature is a very time consuming and resource intensive. Besides that, for us it was not possible to analyze the feasibility of other also important but not so essential features such as model uncertainty and model transparency due to the very limited project period and the very low domain skills at the very beginning of the project.  

\section{Thoughts on the project}
%TODO bitte meine gedanken ueberlesen die sind zu negativ.
\par
Right from the beginning we thought that the execution of the topic was difficult and challenging, and so it was. This had foremost two reasons, namely our lack of knowledge and experience with environmental modelling in general and the explorative nature of the topic.
\par
As we did not really know how to start, we thought and hoped it would be enough to read the provided papers by Athanasiadis and then somehow solve the problem. We soon realised that this idea was very naive and would not work. Due to this our general approach became, without explicitly planning it, to read in a topic, think about it and according to this read more. To become more concrete, the read in process consisted in reading papers and articles about environmental modelling in general and, later on, specific problems like generating an OOM from an ontologie. After this phase, we reflected and discussed about the newly gained knowledge and worked out some ideas. Normally these ideas brought up some other problems or their feasibility had to be checked. In both cases further research on our side was necessary.\\
The binding of the DSL and the ontologie is a good example for this. We came up with the idea that the binding like described above must be necessary for our project and so we looked for references, which describe something similar and fortunately we found them. With these references we were able to refine our ideas and see problems, which were previously unknown to us.\\
In a next step, these new problems could be attacked with further reading and thinking.
To use an anthology to describe the project, it was similar to a jigsaw puzzle with hidden pieces and every single piece had to be found and used in the right place. Unfortunately the puzzle is not complete yet, but at least we found some missing parts.
\par
The lack of basic knowledge with environmental modelling was a big obstacle, which could have been eliminated with a preparation project and some guided support. This preparation project could consist for example in understanding and implementing a simple but complex enough existing model. This idea came up several times during the project, but did not succeed as this process was too time consuming. On the other side, we had a preparing lecture, which was helpful and gave us a first insight into the topic. However this lecture had a theoretical nature, so the practical aspects of modelling were missing.
\par
Another obstacle had an organisational nature, namely the rather big team size, which was prescribed by our university. With eight people it was difficult to provide everybody with useful tasks. Furthermore the level of knowledge and the english skills were very different for everybody. This lead to the problem that some finished reading a paper in short time and could start discussing it, whereas others needed significantly more time. In the beginning the only solution was to wait for everybody to follow-up. Nevertheless this circumstance upsetted both sides, as the one side started discussing about the topic, while the other were still reading. Vice versa the faster group had to wait until the other group finished reading, and could not work during that time. Fortunately this did not lead to bigger arguments and could be later on solved by splitting the tasks according to the individual preferences.
\par
Finally we can state, in spite of all problems, that the project was a good insight in environmental modelling, ontologies, scientific research and feasibility studies, which we could not have learned and experienced in another context during our studies.
















